{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "sequence_length=16\n",
    "batch_size=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define scalers for velocity and timing features\n",
    "pitch_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "velocity_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "start_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "duration_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MIDI features (limited to first 50 notes)\n",
    "def extract_midi_features(midi_file, max_notes=50):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    notes = []  # Initialize notes inside the function\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append([\n",
    "                note.pitch, \n",
    "                note.velocity,\n",
    "                note.start, \n",
    "                note.end - note.start\n",
    "            ])\n",
    "            if len(notes) >= max_notes:  # Stop collecting after 50 notes\n",
    "                return np.array(notes)  # Return early\n",
    "\n",
    "    return np.array(notes[:max_notes])  # Ensure no more than 50 notes\n",
    "\n",
    "# Load all MIDI files (including both .midi and .mid)\n",
    "midi_files = glob.glob(\"smaller-dataset/*.midi\") + glob.glob(\"smaller-dataset/*.mid\")\n",
    "data = []\n",
    "\n",
    "for f in midi_files:\n",
    "    notes = extract_midi_features(f)\n",
    "    for i in range(0, len(notes) - sequence_length - 1):\n",
    "        data.append(notes[i:i + sequence_length])  # Create 16-note sequences\n",
    "\n",
    "data = [d for d in data if d.shape == (sequence_length, 4)]  # Filter inconsistent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n",
      "[[38.         65.          1.02083333  0.19401042]\n",
      " [41.         68.          1.0625      0.18489583]\n",
      " [45.         72.          1.11067708  0.1484375 ]\n",
      " [50.         82.          1.15364583  0.12239583]\n",
      " [62.         68.          1.16796875  0.11328125]\n",
      " [65.         70.          1.20182292  0.10546875]\n",
      " [69.         75.          1.22786458  0.09375   ]\n",
      " [74.         91.          1.26041667  0.08072917]\n",
      " [74.         87.          1.46223958  0.05598958]\n",
      " [62.         84.          1.6171875   0.1328125 ]\n",
      " [50.         73.          1.63020833  0.12369792]\n",
      " [53.         74.          1.63020833  0.14973958]\n",
      " [74.         92.          1.62369792  0.17447917]\n",
      " [70.         78.          1.8046875   0.04947917]\n",
      " [82.         84.          1.79557292  0.06901042]\n",
      " [70.         83.          1.95572917  0.02734375]]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[(16*4)+2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.tensor(np.array(data), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([495, 16, 4])\n",
      "tensor([[7.4000e+01, 9.2000e+01, 1.0234e+00, 6.2500e-02],\n",
      "        [5.7000e+01, 7.9000e+01, 2.0312e+00, 6.3802e-02],\n",
      "        [6.2000e+01, 8.6000e+01, 2.5339e+00, 4.2969e-02],\n",
      "        [8.1000e+01, 9.3000e+01, 1.5456e+00, 1.0534e+00],\n",
      "        [7.4000e+01, 8.2000e+01, 3.0247e+00, 4.4661e-01],\n",
      "        [7.8000e+01, 9.7000e+01, 3.0156e+00, 5.1432e-01],\n",
      "        [7.3000e+01, 7.3000e+01, 3.5182e+00, 4.4271e-02],\n",
      "        [7.6000e+01, 7.9000e+01, 3.5273e+00, 4.9479e-02],\n",
      "        [7.1000e+01, 7.8000e+01, 3.6615e+00, 3.9062e-02],\n",
      "        [7.4000e+01, 7.2000e+01, 3.6667e+00, 4.8177e-02],\n",
      "        [6.9000e+01, 7.6000e+01, 3.7969e+00, 3.1250e-02],\n",
      "        [7.3000e+01, 7.9000e+01, 3.7852e+00, 7.1615e-02],\n",
      "        [6.7000e+01, 7.8000e+01, 3.9284e+00, 3.7760e-02],\n",
      "        [7.1000e+01, 8.3000e+01, 3.9271e+00, 5.7292e-02],\n",
      "        [6.6000e+01, 7.6000e+01, 4.0638e+00, 3.5156e-02],\n",
      "        [6.9000e+01, 7.7000e+01, 4.0625e+00, 5.0781e-02]])\n",
      "[[73.         58.         10.618489    0.6510417 ]\n",
      " [50.         34.         11.428386    0.91015625]\n",
      " [71.         55.         11.0078125   1.3893229 ]\n",
      " [69.         54.         12.186198    0.3216146 ]\n",
      " [50.         27.         13.1432295   0.5546875 ]\n",
      " [68.         60.         13.0286455   1.046875  ]\n",
      " [59.         35.         13.1223955   1.6367188 ]\n",
      " [76.         65.         13.8151045   1.6419271 ]\n",
      " [49.         35.         14.5963545   0.9401042 ]\n",
      " [57.         37.         14.558594    0.98828125]\n",
      " [73.         59.         15.286458    0.2903646 ]\n",
      " [68.         60.         16.059896    0.85286456]\n",
      " [57.         31.         16.125       0.9270833 ]\n",
      " [69.         51.         16.799479    0.30859375]\n",
      " [49.         37.         16.11849     1.0013021 ]\n",
      " [63.         55.         17.5625      0.8828125 ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset[0])\n",
    "print(dataset[50].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch training\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Transformer Model with Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #def __init__(self, d_model, max_len=16):\n",
    "    def __init__(self, d_model, max_len=sequence_length):\n",
    "\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe.to(x.device)\n",
    "\n",
    "class MidiTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=4, model_dim=128, num_heads=4, num_layers=3, ff_dim=512):\n",
    "        super(MidiTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=ff_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(model_dim, input_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = self.pos_encoder(x)  \n",
    "        x = self.transformer_encoder(x)  \n",
    "        x = self.fc(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1764.2919154013357\n",
      "Epoch 10, Loss: 138.45356393629504\n",
      "Epoch 20, Loss: 72.95742650185862\n",
      "Epoch 30, Loss: 65.25593456145256\n",
      "Epoch 40, Loss: 73.22924146344585\n"
     ]
    }
   ],
   "source": [
    "# Model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MidiTransformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with batches\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)  # Move batch to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)  \n",
    "        loss = criterion(outputs, batch)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[66.655304   76.472046    3.10779     0.15729153]\n",
      "  [67.4954     61.187046    3.6697247  -0.00852437]\n",
      "  [59.087944   81.47005     2.634015    0.24200407]\n",
      "  [66.74821    76.41547     3.1049583   0.10729881]\n",
      "  [50.01523    78.80029     3.897826    0.14262837]\n",
      "  [68.166725   68.31609     3.369052    0.1114278 ]\n",
      "  [64.757774   79.75812     2.772558    0.2787254 ]\n",
      "  [67.25861    75.00051     3.0400655   0.14565119]\n",
      "  [63.20275    79.9392      3.2804787   0.0386076 ]\n",
      "  [67.47527    61.77985     3.6242344  -0.02351683]\n",
      "  [66.02391    77.57994     2.708847    0.1444951 ]\n",
      "  [66.98171    59.27022     4.3225393   0.13257444]\n",
      "  [67.9017     64.26326     3.7428174   0.2701029 ]\n",
      "  [64.32998    49.909325    4.7993164   0.03800549]\n",
      "  [67.40578    65.8104      4.0641675   0.08196817]\n",
      "  [66.919304   54.435932    5.1972284   0.11293875]]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a new MIDI sequence from a random input\n",
    "random_index = np.random.randint(0, len(dataset))\n",
    "random_sequence = dataset[random_index].unsqueeze(0)\n",
    "random_sequence = random_sequence.to(device)  # Move input to same device\n",
    "generated_sequence = model(random_sequence).detach().cpu().numpy()\n",
    "\n",
    "print(generated_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note(start=0.473775, end=0.631066, pitch=66, velocity=76)\n",
      "Note(start=1.035710, end=1.027185, pitch=67, velocity=61)\n",
      "Note(start=0.000000, end=0.242004, pitch=59, velocity=81)\n",
      "Note(start=0.470943, end=0.578242, pitch=66, velocity=76)\n",
      "Note(start=1.263811, end=1.406439, pitch=50, velocity=78)\n",
      "Note(start=0.735037, end=0.846465, pitch=68, velocity=68)\n",
      "Note(start=0.138543, end=0.417268, pitch=64, velocity=79)\n",
      "Note(start=0.406050, end=0.551702, pitch=67, velocity=75)\n",
      "Note(start=0.646464, end=0.685071, pitch=63, velocity=79)\n",
      "Note(start=0.990219, end=0.966703, pitch=67, velocity=61)\n",
      "Note(start=0.074832, end=0.219327, pitch=66, velocity=77)\n",
      "Note(start=1.688524, end=1.821099, pitch=66, velocity=59)\n",
      "Note(start=1.108802, end=1.378905, pitch=67, velocity=64)\n",
      "Note(start=2.165301, end=2.203307, pitch=64, velocity=49)\n",
      "Note(start=1.430152, end=1.512121, pitch=67, velocity=65)\n",
      "Note(start=2.563213, end=2.676152, pitch=66, velocity=54)\n",
      "Generated MIDI saved as generated.mid\n"
     ]
    }
   ],
   "source": [
    "# Convert generated sequence to MIDI\n",
    "def sequence_to_midi(sequence, output_file=\"generated.mid\"):\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=0)  \n",
    "\n",
    "    # Adjust start times to ensure the sequence starts at 0\n",
    "    min_start_time = min(note_data[2] for note_data in sequence[0])\n",
    "    \n",
    "    for note_data in sequence[0]:  # Adjusted to handle batch dimension\n",
    "        pitch, velocity, start, duration = note_data\n",
    "        pitch = int(pitch)  # Ensure pitch is an integer\n",
    "        velocity = int(velocity)  # Ensure velocity is an integer\n",
    "        start = float(start) - min_start_time  # Adjust start time\n",
    "        duration = float(duration)  # Ensure duration is a float\n",
    "        end = start + duration\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=velocity, pitch=pitch, start=start, end=end\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    midi.instruments.append(instrument)\n",
    "    midi.write(output_file)\n",
    "    for noteInformation in midi.instruments[0].notes:\n",
    "        print(noteInformation)\n",
    "    print(f\"Generated MIDI saved as {output_file}\")\n",
    "\n",
    "sequence_to_midi(generated_sequence, \"generated.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
