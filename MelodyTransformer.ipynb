{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLimit=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define scalers for velocity and timing features\n",
    "velocity_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "time_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract MIDI features\n",
    "def extract_midi_features(midi_file):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    notes = []  # Initialize notes inside the function\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append([\n",
    "                note.pitch, \n",
    "                note.velocity,\n",
    "                note.start, \n",
    "                note.end-note.start \n",
    "            ])\n",
    "    \n",
    "    return np.array(notes)  # Return all notes\n",
    "\n",
    "# Load all MIDI files\n",
    "midi_files = glob.glob(\"smaller-dataset/*.midi\")\n",
    "data = []\n",
    "for f in midi_files:\n",
    "    notes = extract_midi_features(f)\n",
    "    for i in range(0, len(notes) - 15):\n",
    "        data.append(notes[i:i+16])  # Create 16-note sequences\n",
    "data = [d for d in data if d.shape == (16, 4)]  # Filter inconsistent samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 16, 4])\n",
      "tensor([[7.4000e+01, 9.2000e+01, 1.0234e+00, 6.2500e-02],\n",
      "        [5.7000e+01, 7.9000e+01, 2.0312e+00, 6.3802e-02],\n",
      "        [6.2000e+01, 8.6000e+01, 2.5339e+00, 4.2969e-02],\n",
      "        [8.1000e+01, 9.3000e+01, 1.5456e+00, 1.0534e+00],\n",
      "        [7.4000e+01, 8.2000e+01, 3.0247e+00, 4.4661e-01],\n",
      "        [7.8000e+01, 9.7000e+01, 3.0156e+00, 5.1432e-01],\n",
      "        [7.3000e+01, 7.3000e+01, 3.5182e+00, 4.4271e-02],\n",
      "        [7.6000e+01, 7.9000e+01, 3.5273e+00, 4.9479e-02],\n",
      "        [7.1000e+01, 7.8000e+01, 3.6615e+00, 3.9062e-02],\n",
      "        [7.4000e+01, 7.2000e+01, 3.6667e+00, 4.8177e-02],\n",
      "        [6.9000e+01, 7.6000e+01, 3.7969e+00, 3.1250e-02],\n",
      "        [7.3000e+01, 7.9000e+01, 3.7852e+00, 7.1615e-02],\n",
      "        [6.7000e+01, 7.8000e+01, 3.9284e+00, 3.7760e-02],\n",
      "        [7.1000e+01, 8.3000e+01, 3.9271e+00, 5.7292e-02],\n",
      "        [6.6000e+01, 7.6000e+01, 4.0638e+00, 3.5156e-02],\n",
      "        [6.9000e+01, 7.7000e+01, 4.0625e+00, 5.0781e-02]])\n"
     ]
    }
   ],
   "source": [
    "data = data[:sequenceLimit]\n",
    "dataset = torch.tensor(np.array(data), dtype=torch.float32)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print(dataset.shape)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch training\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Transformer Model with Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=16):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe.to(x.device)\n",
    "\n",
    "class MidiTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=4, model_dim=128, num_heads=4, num_layers=3, ff_dim=512):\n",
    "        super(MidiTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=ff_dim\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(model_dim, input_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = self.pos_encoder(x)  \n",
    "        x = self.transformer_encoder(x)  \n",
    "        x = self.fc(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ugur\\Development\\jupyterlab\\MelodyTransformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 39.35063195228577\n",
      "Epoch 10, Loss: 19.882048726081848\n",
      "Epoch 20, Loss: 3.9847057461738586\n",
      "Epoch 30, Loss: 2.1883397921919823\n",
      "Epoch 40, Loss: 1.5797059908509254\n",
      "Epoch 50, Loss: 1.2809944078326225\n",
      "Epoch 60, Loss: 1.150880753993988\n",
      "Epoch 70, Loss: 1.0622083991765976\n",
      "Epoch 80, Loss: 1.0230532139539719\n",
      "Epoch 90, Loss: 0.9688814021646976\n"
     ]
    }
   ],
   "source": [
    "# Model, loss function, and optimizer\n",
    "model = MidiTransformer()\n",
    "criterion = nn.MSELoss()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with batches\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)  \n",
    "        loss = criterion(outputs, batch)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7.4000e+01, 8.7000e+01, 4.7186e+01, 9.5052e-02],\n",
      "         [7.6000e+01, 7.6000e+01, 4.7268e+01, 9.6354e-02],\n",
      "         [6.2000e+01, 8.1000e+01, 4.7331e+01, 5.4688e-02],\n",
      "         [7.8000e+01, 9.9000e+01, 4.7339e+01, 7.0312e-02],\n",
      "         [6.4000e+01, 8.0000e+01, 4.7579e+01, 5.7292e-02],\n",
      "         [8.0000e+01, 8.7000e+01, 4.7579e+01, 9.5052e-02],\n",
      "         [6.6000e+01, 8.9000e+01, 4.7810e+01, 7.0312e-02],\n",
      "         [8.1000e+01, 8.3000e+01, 4.7809e+01, 1.2370e-01],\n",
      "         [8.0000e+01, 7.8000e+01, 4.7909e+01, 1.2109e-01],\n",
      "         [7.8000e+01, 8.2000e+01, 4.8000e+01, 1.6146e-01],\n",
      "         [7.6000e+01, 7.9000e+01, 4.8104e+01, 9.2448e-02],\n",
      "         [6.2000e+01, 8.0000e+01, 4.8208e+01, 8.2031e-02],\n",
      "         [7.4000e+01, 8.3000e+01, 4.8208e+01, 1.1719e-01],\n",
      "         [7.3000e+01, 8.3000e+01, 4.8324e+01, 1.2760e-01],\n",
      "         [7.1000e+01, 7.9000e+01, 4.8431e+01, 9.1146e-02],\n",
      "         [6.9000e+01, 7.6000e+01, 4.8535e+01, 1.5365e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# Generate a new MIDI sequence from a random input\n",
    "\n",
    "random_index = np.random.randint(0, len(dataset))\n",
    "random_sequence = dataset[random_index].unsqueeze(0)\n",
    "\n",
    "print(random_sequence) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[69.67848   , 77.24085   , 43.734467  ,  0.08995359],\n",
       "        [71.08682   , 70.62157   , 43.540554  ,  0.0734554 ],\n",
       "        [62.674156  , 77.625496  , 45.823338  ,  0.03369004],\n",
       "        [69.77228   , 85.28928   , 41.819225  ,  0.06462853],\n",
       "        [64.100845  , 78.56765   , 47.167805  , -0.00189007],\n",
       "        [72.8452    , 75.545845  , 42.21764   ,  0.09657156],\n",
       "        [63.909595  , 80.037926  , 44.594505  ,  0.03622627],\n",
       "        [70.967255  , 71.6163    , 40.73186   ,  0.09243037],\n",
       "        [71.590485  , 68.77719   , 42.228886  ,  0.13451473],\n",
       "        [70.71718   , 71.53368   , 42.364616  , -0.01942845],\n",
       "        [70.60805   , 71.46923   , 42.957943  ,  0.08632839],\n",
       "        [63.822342  , 74.28846   , 46.749096  ,  0.08174405],\n",
       "        [69.42537   , 76.87594   , 44.60462   ,  0.03748   ],\n",
       "        [69.20035   , 76.25457   , 45.10779   ,  0.04036448],\n",
       "        [68.52671   , 73.507225  , 45.405888  , -0.0301188 ],\n",
       "        [67.16599   , 70.19746   , 45.853695  ,  0.04409356]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sequence = model(random_sequence).detach().numpy()\n",
    "generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Note(start=3.002605, end=3.092559, pitch=69, velocity=77), Note(start=2.808693, end=2.882148, pitch=71, velocity=70), Note(start=5.091476, end=5.125166, pitch=62, velocity=77), Note(start=1.087364, end=1.151993, pitch=69, velocity=85), Note(start=6.435944, end=6.434053, pitch=64, velocity=78), Note(start=1.485779, end=1.582350, pitch=72, velocity=75), Note(start=3.862644, end=3.898870, pitch=63, velocity=80), Note(start=0.000000, end=0.092430, pitch=70, velocity=71), Note(start=1.497025, end=1.631539, pitch=71, velocity=68), Note(start=1.632755, end=1.613327, pitch=70, velocity=71), Note(start=2.226082, end=2.312410, pitch=70, velocity=71), Note(start=6.017235, end=6.098979, pitch=63, velocity=74), Note(start=3.872761, end=3.910241, pitch=69, velocity=76), Note(start=4.375931, end=4.416295, pitch=69, velocity=76), Note(start=4.674026, end=4.643908, pitch=68, velocity=73), Note(start=5.121834, end=5.165927, pitch=67, velocity=70)]\n",
      "Generated MIDI saved as generated.mid\n"
     ]
    }
   ],
   "source": [
    "# Convert generated sequence to MIDI\n",
    "def sequence_to_midi(sequence, output_file=\"generated.mid\"):\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=0)  \n",
    "\n",
    "    # Adjust the start times to ensure the sequence starts at 0\n",
    "    min_start_time = min(note_data[2] for note_data in sequence)\n",
    "    \n",
    "    for note_data in sequence:\n",
    "        pitch, velocity = map(int, note_data[:2])\n",
    "        start, duration = map(float, note_data[2:])\n",
    "        start -= min_start_time  # Adjust start time to ensure it starts at 0\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=max(0, min(127, velocity)),  \n",
    "            pitch=max(0, min(127, pitch)),  \n",
    "            start=start,\n",
    "            end=start + duration\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    midi.instruments.append(instrument)\n",
    "    midi.write(output_file)\n",
    "    print(instrument.notes)\n",
    "    print(f\"Generated MIDI saved as {output_file}\")\n",
    "sequence_to_midi(generated_sequence[0], \"generated.mid\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
