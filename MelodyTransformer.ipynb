{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "sequence_length=16\n",
    "batch_size=16\n",
    "max_notes=100\n",
    "dataset_path='smaller-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define scalers for velocity and timing features\n",
    "pitch_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "velocity_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "start_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "duration_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MIDI features (limited to first 50 notes)\n",
    "def extract_midi_features(midi_file):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    notes = []  # Initialize notes inside the function\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append([\n",
    "                note.pitch, \n",
    "                note.velocity,\n",
    "                note.start, \n",
    "                note.end - note.start\n",
    "            ])\n",
    "            if len(notes) >= max_notes:  # Stop collecting after 50 notes\n",
    "                return np.array(notes)  # Return early\n",
    "    return np.array(notes[:max_notes])  # Ensure no more than 50 notes\n",
    "\n",
    "# Load all MIDI files (including both .midi and .mid)\n",
    "midi_files = glob.glob(dataset_path+\"/*.midi\") + glob.glob(dataset_path+\"/*.mid\")\n",
    "data = []\n",
    "\n",
    "for f in midi_files:\n",
    "    notes = extract_midi_features(f)\n",
    "    #print(notes.shape)\n",
    "    #print(len(notes))\n",
    "    #print(len(notes) - sequence_length - 1)\n",
    "    for i in range(0, len(notes) - sequence_length - 1):\n",
    "        data.append(notes[i:i + sequence_length])  # Create 16-note sequences\n",
    "\n",
    "data = [d for d in data if d.shape == (sequence_length, 4)]  # Filter inconsistent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1245, 16, 4])\n",
      "[[74.         92.          1.0234375   0.0625    ]\n",
      " [57.         79.          2.03125     0.06380209]\n",
      " [62.         86.          2.5338542   0.04296875]\n",
      " [81.         93.          1.5455729   1.0533854 ]\n",
      " [74.         82.          3.0247395   0.4466146 ]\n",
      " [78.         97.          3.015625    0.51432294]\n",
      " [73.         73.          3.5182292   0.04427083]\n",
      " [76.         79.          3.5273438   0.04947917]\n",
      " [71.         78.          3.6614583   0.0390625 ]\n",
      " [74.         72.          3.6666667   0.04817708]\n",
      " [69.         76.          3.796875    0.03125   ]\n",
      " [73.         79.          3.7851562   0.07161459]\n",
      " [67.         78.          3.9283855   0.03776042]\n",
      " [71.         83.          3.9270833   0.05729167]\n",
      " [66.         76.          4.0638022   0.03515625]\n",
      " [69.         77.          4.0625      0.05078125]]\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.tensor(np.array(data), dtype=torch.float32)\n",
    "print(dataset.shape)\n",
    "print(dataset[0].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1245, 16, 4])\n",
      "[[0.62673616 0.7791855  0.00845366 0.00051625]\n",
      " [0.5850849  0.8109071  0.01025959 0.00032226]\n",
      " [0.58477557 0.8111403  0.00943051 0.00015992]\n",
      " [0.65675914 0.7540568  0.0067     0.00456639]\n",
      " [0.6699371  0.7423627  0.0089561  0.0013224 ]\n",
      " [0.62663233 0.77927357 0.00791939 0.00135067]\n",
      " [0.7070736  0.7070736  0.00968517 0.00012187]\n",
      " [0.69326216 0.7206278  0.00912097 0.00012794]\n",
      " [0.6731143  0.7394777  0.00947994 0.00010114]\n",
      " [0.7166923  0.69732225 0.00968419 0.00012724]\n",
      " [0.67215586 0.7403456  0.00974106 0.00008017]\n",
      " [0.67863685 0.7344152  0.00929473 0.00017585]\n",
      " [0.6515611  0.75853384 0.00972434 0.00009347]\n",
      " [0.6500098  0.75987065 0.00915409 0.00013355]\n",
      " [0.6556543  0.7549959  0.00993378 0.00008594]\n",
      " [0.6673289  0.7447004  0.00967068 0.00012088]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the dataset for only start and end columns\n",
    "\n",
    "\n",
    "# Compute L2 norm for the last two columns **before** normalization\n",
    "#original_norms = torch.norm(dataset[:, :, 2:], p=2, dim=2, keepdim=True)\n",
    "\n",
    "# Apply L2 normalization only to the last two columns along `dim=2`\n",
    "#normalized_floats = F.normalize(dataset[:, :, 2:], p=2, dim=2)\n",
    "\n",
    "# Combine integer columns and normalized float columns\n",
    "#normalized_tensor = torch.cat((dataset[:, :, :2], normalized_floats), dim=2)\n",
    "\n",
    "\n",
    "# Normalize the dataset for all columns\n",
    "\n",
    "\n",
    "# Compute L2 norm for all 4 columns along `dim=2`\n",
    "original_norms = torch.norm(dataset, p=2, dim=2, keepdim=True)  # Shape (n, 16, 1)\n",
    "\n",
    "# Normalize by dividing each column by its L2 norm\n",
    "normalized_tensor = dataset / (original_norms + 1e-8)  # Avoid division by zero\n",
    "\n",
    "\n",
    "print(normalized_tensor.shape)\n",
    "print(normalized_tensor[0].numpy())\n",
    "\n",
    "dataset = normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch training\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Transformer Model with Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #def __init__(self, d_model, max_len=16):\n",
    "    def __init__(self, d_model, max_len=sequence_length):\n",
    "\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe.to(x.device)\n",
    "\n",
    "class MidiTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=4, model_dim=128, num_heads=4, num_layers=3, ff_dim=512):\n",
    "        super(MidiTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=ff_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(model_dim, input_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = self.pos_encoder(x)  \n",
    "        x = self.transformer_encoder(x)  \n",
    "        x = self.fc(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.06967059296006575\n",
      "Epoch 10, Loss: 0.0008469862409700186\n",
      "Epoch 20, Loss: 0.001085345895822124\n",
      "Epoch 30, Loss: 0.0003567144606047525\n",
      "Epoch 40, Loss: 0.00042770833608348115\n"
     ]
    }
   ],
   "source": [
    "# Model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MidiTransformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with batches\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)  # Move batch to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)  \n",
    "        loss = criterion(outputs, batch)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.636406    0.7917115   0.00350369 -0.00241182]\n",
      " [ 0.5794409   0.81270367 -0.00222071  0.00358654]\n",
      " [ 0.6022088   0.80662715  0.00383696 -0.00620071]\n",
      " [ 0.654855    0.7430473  -0.00030951  0.00388243]\n",
      " [ 0.65601045  0.7563926   0.00329684  0.00259059]\n",
      " [ 0.6143858   0.77904606  0.00252246  0.00500582]\n",
      " [ 0.70056057  0.70913094  0.0074934   0.00213918]\n",
      " [ 0.69353664  0.720341    0.00916249 -0.00242757]\n",
      " [ 0.67089057  0.74255204  0.00305285  0.00013651]\n",
      " [ 0.70257676  0.6913601   0.00609456 -0.00663397]\n",
      " [ 0.6643923   0.7486783   0.00866148  0.00852416]\n",
      " [ 0.67919576  0.7362311   0.00467242 -0.0046528 ]\n",
      " [ 0.6516422   0.75461155  0.00669618  0.00458929]\n",
      " [ 0.65871984  0.7699835   0.0026414   0.00095144]\n",
      " [ 0.6431219   0.7620988   0.00492819  0.00492529]\n",
      " [ 0.67372376  0.7403782   0.00528182 -0.00007175]]\n",
      "[[75.14174    93.47897     0.4136879  -0.2847681 ]\n",
      " [56.450153   79.175026   -0.21634573  0.3494075 ]\n",
      " [63.848335   85.5215      0.4068082  -0.6574214 ]\n",
      " [80.76516    91.642166   -0.03817301  0.4788317 ]\n",
      " [72.46169    83.54972     0.3641633   0.28615156]\n",
      " [76.47561    96.97168     0.31398308  0.6230987 ]\n",
      " [72.327576   73.2124      0.7736371   0.22085366]\n",
      " [76.03009    78.96857     1.0044525  -0.2661261 ]\n",
      " [70.76544    78.32429     0.3220145   0.0143991 ]\n",
      " [72.54254    71.3844      0.6292763  -0.68497187]\n",
      " [68.20303    76.85539     0.88914204  0.8750461 ]\n",
      " [73.06013    79.195335    0.5026051  -0.500495  ]\n",
      " [67.00834    77.59667     0.6885678   0.47191623]\n",
      " [71.951385   84.104614    0.28851804  0.10392486]\n",
      " [64.73846    76.715004    0.49608582  0.4957936 ]\n",
      " [69.66121    76.5531      0.546126   -0.00741895]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a new MIDI sequence from a random input\n",
    "random_index = np.random.randint(0, len(dataset))\n",
    "#random_sequence = dataset[random_index].unsqueeze(0)\n",
    "random_sequence = dataset[0].unsqueeze(0)\n",
    "\n",
    "random_sequence = random_sequence.to(device)  # Move input to same device\n",
    "generated_sequence = model(random_sequence).detach().cpu()\n",
    "\n",
    "print(generated_sequence[0].numpy())\n",
    "generated_sequence  = generated_sequence * original_norms  # Restore original values\n",
    "generated_sequence = generated_sequence.numpy()\n",
    "print(generated_sequence[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note(start=0.630034, end=0.345266, pitch=75, velocity=93)\n",
      "Note(start=0.000000, end=0.349407, pitch=56, velocity=79)\n",
      "Note(start=0.623154, end=-0.034267, pitch=63, velocity=85)\n",
      "Note(start=0.178173, end=0.657004, pitch=80, velocity=91)\n",
      "Note(start=0.580509, end=0.866661, pitch=72, velocity=83)\n",
      "Note(start=0.530329, end=1.153427, pitch=76, velocity=96)\n",
      "Note(start=0.989983, end=1.210837, pitch=72, velocity=73)\n",
      "Note(start=1.220798, end=0.954672, pitch=76, velocity=78)\n",
      "Note(start=0.538360, end=0.552759, pitch=70, velocity=78)\n",
      "Note(start=0.845622, end=0.160650, pitch=72, velocity=71)\n",
      "Note(start=1.105488, end=1.980534, pitch=68, velocity=76)\n",
      "Note(start=0.718951, end=0.218456, pitch=73, velocity=79)\n",
      "Note(start=0.904914, end=1.376830, pitch=67, velocity=77)\n",
      "Note(start=0.504864, end=0.608789, pitch=71, velocity=84)\n",
      "Note(start=0.712432, end=1.208225, pitch=64, velocity=76)\n",
      "Note(start=0.762472, end=0.755053, pitch=69, velocity=76)\n",
      "Generated MIDI saved as generated.mid\n"
     ]
    }
   ],
   "source": [
    "# Convert generated sequence to MIDI\n",
    "def sequence_to_midi(sequence, output_file=\"generated.mid\"):\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=0)  \n",
    "\n",
    "    # Adjust start times to ensure the sequence starts at 0\n",
    "    min_start_time = min(note_data[2] for note_data in sequence[0])\n",
    "    \n",
    "    for note_data in sequence[0]:  # Adjusted to handle batch dimension\n",
    "        pitch, velocity, start, duration = note_data\n",
    "        pitch = int(pitch)  # Ensure pitch is an integer\n",
    "        velocity = int(velocity)  # Ensure velocity is an integer\n",
    "        start = float(start) - min_start_time  # Adjust start time\n",
    "        duration = float(duration)  # Ensure duration is a float\n",
    "        end = start + duration\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=velocity, pitch=pitch, start=start, end=end\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    midi.instruments.append(instrument)\n",
    "    midi.write(output_file)\n",
    "    for noteInformation in midi.instruments[0].notes:\n",
    "        print(noteInformation)\n",
    "    print(f\"Generated MIDI saved as {output_file}\")\n",
    "\n",
    "sequence_to_midi(generated_sequence, \"generated.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
