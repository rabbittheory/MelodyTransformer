{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "sequence_length=16\n",
    "batch_size=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define scalers for velocity and timing features\n",
    "pitch_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "velocity_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "start_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "duration_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MIDI features (limited to first 50 notes)\n",
    "def extract_midi_features(midi_file, max_notes=50):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    notes = []  # Initialize notes inside the function\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append([\n",
    "                note.pitch, \n",
    "                note.velocity,\n",
    "                note.start, \n",
    "                note.end - note.start\n",
    "            ])\n",
    "            if len(notes) >= max_notes:  # Stop collecting after 50 notes\n",
    "                return np.array(notes)  # Return early\n",
    "\n",
    "    return np.array(notes[:max_notes])  # Ensure no more than 50 notes\n",
    "\n",
    "# Load all MIDI files (including both .midi and .mid)\n",
    "midi_files = glob.glob(\"smaller-dataset/*.midi\") + glob.glob(\"smaller-dataset/*.mid\")\n",
    "data = []\n",
    "\n",
    "for f in midi_files:\n",
    "    notes = extract_midi_features(f)\n",
    "    for i in range(0, len(notes) - sequence_length - 1):\n",
    "        data.append(notes[i:i + sequence_length])  # Create 16-note sequences\n",
    "\n",
    "data = [d for d in data if d.shape == (sequence_length, 4)]  # Filter inconsistent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n",
      "[[38.         65.          1.02083333  0.19401042]\n",
      " [41.         68.          1.0625      0.18489583]\n",
      " [45.         72.          1.11067708  0.1484375 ]\n",
      " [50.         82.          1.15364583  0.12239583]\n",
      " [62.         68.          1.16796875  0.11328125]\n",
      " [65.         70.          1.20182292  0.10546875]\n",
      " [69.         75.          1.22786458  0.09375   ]\n",
      " [74.         91.          1.26041667  0.08072917]\n",
      " [74.         87.          1.46223958  0.05598958]\n",
      " [62.         84.          1.6171875   0.1328125 ]\n",
      " [50.         73.          1.63020833  0.12369792]\n",
      " [53.         74.          1.63020833  0.14973958]\n",
      " [74.         92.          1.62369792  0.17447917]\n",
      " [70.         78.          1.8046875   0.04947917]\n",
      " [82.         84.          1.79557292  0.06901042]\n",
      " [70.         83.          1.95572917  0.02734375]]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[(16*4)+2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack data for scaling\n",
    "all_data = np.vstack(data)\n",
    "pitch_scaler.fit(all_data[:, 0].reshape(-1, 1))\n",
    "velocity_scaler.fit(all_data[:, 1].reshape(-1, 1))\n",
    "start_scaler.fit(all_data[:, 2].reshape(-1, 1))\n",
    "duration_scaler.fit(all_data[:, 3].reshape(-1, 1))\n",
    "\n",
    "# Apply scaling\n",
    "scaled_data = []\n",
    "for d in data:\n",
    "    scaled_d = np.copy(d)\n",
    "    scaled_d[:, 0] = pitch_scaler.transform(scaled_d[:, 0].reshape(-1, 1)).flatten()\n",
    "    scaled_d[:, 1] = velocity_scaler.transform(scaled_d[:, 1].reshape(-1, 1)).flatten()\n",
    "    scaled_d[:, 2] = start_scaler.transform(scaled_d[:, 2].reshape(-1, 1)).flatten()\n",
    "    scaled_d[:, 3] = duration_scaler.transform(scaled_d[:, 3].reshape(-1, 1)).flatten()\n",
    "    scaled_data.append(scaled_d)\n",
    "\n",
    "dataset = torch.tensor(np.array(scaled_data), dtype=torch.float32)\n",
    "dataset = torch.tensor(np.array(data), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([495, 16, 4])\n",
      "[[73.         58.         10.618489    0.6510417 ]\n",
      " [50.         34.         11.428386    0.91015625]\n",
      " [71.         55.         11.0078125   1.3893229 ]\n",
      " [69.         54.         12.186198    0.3216146 ]\n",
      " [50.         27.         13.1432295   0.5546875 ]\n",
      " [68.         60.         13.0286455   1.046875  ]\n",
      " [59.         35.         13.1223955   1.6367188 ]\n",
      " [76.         65.         13.8151045   1.6419271 ]\n",
      " [49.         35.         14.5963545   0.9401042 ]\n",
      " [57.         37.         14.558594    0.98828125]\n",
      " [73.         59.         15.286458    0.2903646 ]\n",
      " [68.         60.         16.059896    0.85286456]\n",
      " [57.         31.         16.125       0.9270833 ]\n",
      " [69.         51.         16.799479    0.30859375]\n",
      " [49.         37.         16.11849     1.0013021 ]\n",
      " [63.         55.         17.5625      0.8828125 ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "\n",
    "#print(dataset[0])\n",
    "\n",
    "# Print the tensor without scientific notation\n",
    "#print(dataset[990].numpy())\n",
    "print(dataset[50].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch training\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Transformer Model with Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #def __init__(self, d_model, max_len=16):\n",
    "    def __init__(self, d_model, max_len=sequence_length):\n",
    "\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe.to(x.device)\n",
    "\n",
    "class MidiTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=4, model_dim=128, num_heads=4, num_layers=3, ff_dim=512):\n",
    "        super(MidiTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=ff_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(model_dim, input_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = self.pos_encoder(x)  \n",
    "        x = self.transformer_encoder(x)  \n",
    "        x = self.fc(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1769.8519838394657\n",
      "Epoch 10, Loss: 145.14221474432176\n",
      "Epoch 20, Loss: 115.74394226074219\n",
      "Epoch 30, Loss: 97.931216455275\n",
      "Epoch 40, Loss: 79.36224414456275\n"
     ]
    }
   ],
   "source": [
    "# Model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MidiTransformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with batches\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)  # Move batch to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)  \n",
    "        loss = criterion(outputs, batch)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[63.632946   47.56388     6.095802    0.18727013]\n",
      "  [62.614407   46.86259     6.022663    0.11177169]\n",
      "  [65.69594    55.190727    6.0429773   0.3672974 ]\n",
      "  [62.537354   76.7192      4.59267     0.09683529]\n",
      "  [62.508804   44.765778    6.0900426   0.35648322]\n",
      "  [60.97565    74.36569     4.7566695  -0.27469844]\n",
      "  [63.228558   47.360847    6.1258955   0.1333732 ]\n",
      "  [64.1821     48.732655    5.8902307   0.3552083 ]\n",
      "  [63.297733   46.453403    6.0227723   0.14642431]\n",
      "  [63.13791    48.024395    5.689944    0.20530272]\n",
      "  [64.73459    49.957947    5.8427353   0.06333633]\n",
      "  [65.270706   49.259678    6.163333    0.23612222]\n",
      "  [61.424946   44.84435     5.6456966   0.57355386]\n",
      "  [63.011677   49.17625     6.0233083   0.11009887]\n",
      "  [62.417854   46.70301     5.963119    0.20634249]\n",
      "  [62.45598    46.282383    6.090487   -0.02398095]]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a new MIDI sequence from a random input\n",
    "random_index = np.random.randint(0, len(dataset))\n",
    "random_sequence = dataset[random_index].unsqueeze(0)\n",
    "random_sequence = random_sequence.to(device)  # Move input to same device\n",
    "generated_sequence = model(random_sequence).detach().cpu().numpy()\n",
    "\n",
    "# Apply inverse scaling to the generated sequence\n",
    "'''\n",
    "generated_sequence[:, :, 0] = pitch_scaler.inverse_transform(generated_sequence[:, :, 0])\n",
    "generated_sequence[:, :, 1] = velocity_scaler.inverse_transform(generated_sequence[:, :, 1])\n",
    "generated_sequence[:, :, 2] = start_scaler.inverse_transform(generated_sequence[:, :, 2])\n",
    "generated_sequence[:, :, 3] = duration_scaler.inverse_transform(generated_sequence[:, :, 3])\n",
    "'''\n",
    "print(generated_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note(start=1.503132, end=1.690402, pitch=63, velocity=47)\n",
      "Note(start=1.429993, end=1.541765, pitch=62, velocity=46)\n",
      "Note(start=1.450307, end=1.817605, pitch=65, velocity=55)\n",
      "Note(start=0.000000, end=0.096835, pitch=62, velocity=76)\n",
      "Note(start=1.497373, end=1.853856, pitch=62, velocity=44)\n",
      "Note(start=0.164000, end=-0.110699, pitch=60, velocity=74)\n",
      "Note(start=1.533226, end=1.666599, pitch=63, velocity=47)\n",
      "Note(start=1.297561, end=1.652769, pitch=64, velocity=48)\n",
      "Note(start=1.430102, end=1.576527, pitch=63, velocity=46)\n",
      "Note(start=1.097274, end=1.302577, pitch=63, velocity=48)\n",
      "Note(start=1.250065, end=1.313402, pitch=64, velocity=49)\n",
      "Note(start=1.570663, end=1.806785, pitch=65, velocity=49)\n",
      "Note(start=1.053027, end=1.626580, pitch=61, velocity=44)\n",
      "Note(start=1.430638, end=1.540737, pitch=63, velocity=49)\n",
      "Note(start=1.370449, end=1.576792, pitch=62, velocity=46)\n",
      "Note(start=1.497817, end=1.473836, pitch=62, velocity=46)\n",
      "Generated MIDI saved as generated.mid\n"
     ]
    }
   ],
   "source": [
    "# Convert generated sequence to MIDI\n",
    "def sequence_to_midi(sequence, output_file=\"generated.mid\"):\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=0)  \n",
    "\n",
    "    # Adjust start times to ensure the sequence starts at 0\n",
    "    min_start_time = min(note_data[2] for note_data in sequence[0])\n",
    "    \n",
    "    for note_data in sequence[0]:  # Adjusted to handle batch dimension\n",
    "        pitch, velocity, start, duration = note_data\n",
    "        pitch = int(pitch)  # Ensure pitch is an integer\n",
    "        velocity = int(velocity)  # Ensure velocity is an integer\n",
    "        start = float(start) - min_start_time  # Adjust start time\n",
    "        duration = float(duration)  # Ensure duration is a float\n",
    "        end = start + duration\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=velocity, pitch=pitch, start=start, end=end\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    midi.instruments.append(instrument)\n",
    "    midi.write(output_file)\n",
    "    for noteInformation in midi.instruments[0].notes:\n",
    "        print(noteInformation)\n",
    "    print(f\"Generated MIDI saved as {output_file}\")\n",
    "\n",
    "sequence_to_midi(generated_sequence, \"generated.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
