{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "sequence_length=16\n",
    "batch_size=16\n",
    "max_notes=100\n",
    "dataset_path='smaller-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define scalers for velocity and timing features\n",
    "pitch_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "velocity_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "start_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "duration_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MIDI features (limited to first 50 notes)\n",
    "def extract_midi_features(midi_file):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    notes = []  # Initialize notes inside the function\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append([\n",
    "                note.pitch, \n",
    "                note.velocity,\n",
    "                note.start, \n",
    "                note.end - note.start\n",
    "            ])\n",
    "            if len(notes) >= max_notes:  # Stop collecting after 50 notes\n",
    "                return np.array(notes)  # Return early\n",
    "    return np.array(notes[:max_notes])  # Ensure no more than 50 notes\n",
    "\n",
    "# Load all MIDI files (including both .midi and .mid)\n",
    "midi_files = glob.glob(dataset_path+\"/*.midi\") + glob.glob(dataset_path+\"/*.mid\")\n",
    "data = []\n",
    "\n",
    "for f in midi_files:\n",
    "    notes = extract_midi_features(f)\n",
    "    #print(notes.shape)\n",
    "    #print(len(notes))\n",
    "    #print(len(notes) - sequence_length - 1)\n",
    "    for i in range(0, len(notes) - sequence_length - 1):\n",
    "        data.append(notes[i:i + sequence_length])  # Create 16-note sequences\n",
    "\n",
    "data = [d for d in data if d.shape == (sequence_length, 4)]  # Filter inconsistent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1245, 16, 4])\n",
      "[[74.         92.          1.0234375   0.0625    ]\n",
      " [57.         79.          2.03125     0.06380209]\n",
      " [62.         86.          2.5338542   0.04296875]\n",
      " [81.         93.          1.5455729   1.0533854 ]\n",
      " [74.         82.          3.0247395   0.4466146 ]\n",
      " [78.         97.          3.015625    0.51432294]\n",
      " [73.         73.          3.5182292   0.04427083]\n",
      " [76.         79.          3.5273438   0.04947917]\n",
      " [71.         78.          3.6614583   0.0390625 ]\n",
      " [74.         72.          3.6666667   0.04817708]\n",
      " [69.         76.          3.796875    0.03125   ]\n",
      " [73.         79.          3.7851562   0.07161459]\n",
      " [67.         78.          3.9283855   0.03776042]\n",
      " [71.         83.          3.9270833   0.05729167]\n",
      " [66.         76.          4.0638022   0.03515625]\n",
      " [69.         77.          4.0625      0.05078125]]\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.tensor(np.array(data), dtype=torch.float32)\n",
    "print(dataset.shape)\n",
    "print(dataset[0].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1245, 16, 4])\n",
      "[[0.62673616 0.7791855  0.00845366 0.00051625]\n",
      " [0.5850849  0.8109071  0.01025959 0.00032226]\n",
      " [0.58477557 0.8111403  0.00943051 0.00015992]\n",
      " [0.65675914 0.7540568  0.0067     0.00456639]\n",
      " [0.6699371  0.7423627  0.0089561  0.0013224 ]\n",
      " [0.62663233 0.77927357 0.00791939 0.00135067]\n",
      " [0.7070736  0.7070736  0.00968517 0.00012187]\n",
      " [0.69326216 0.7206278  0.00912097 0.00012794]\n",
      " [0.6731143  0.7394777  0.00947994 0.00010114]\n",
      " [0.7166923  0.69732225 0.00968419 0.00012724]\n",
      " [0.67215586 0.7403456  0.00974106 0.00008017]\n",
      " [0.67863685 0.7344152  0.00929473 0.00017585]\n",
      " [0.6515611  0.75853384 0.00972434 0.00009347]\n",
      " [0.6500098  0.75987065 0.00915409 0.00013355]\n",
      " [0.6556543  0.7549959  0.00993378 0.00008594]\n",
      " [0.6673289  0.7447004  0.00967068 0.00012088]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the dataset for only start and end columns\n",
    "\n",
    "\n",
    "# Compute L2 norm for the last two columns **before** normalization\n",
    "#original_norms = torch.norm(dataset[:, :, 2:], p=2, dim=2, keepdim=True)\n",
    "\n",
    "# Apply L2 normalization only to the last two columns along `dim=2`\n",
    "#normalized_floats = F.normalize(dataset[:, :, 2:], p=2, dim=2)\n",
    "\n",
    "# Combine integer columns and normalized float columns\n",
    "#normalized_tensor = torch.cat((dataset[:, :, :2], normalized_floats), dim=2)\n",
    "\n",
    "\n",
    "# Normalize the dataset for all columns\n",
    "\n",
    "\n",
    "# Compute L2 norm for all 4 columns along `dim=2`\n",
    "original_norms = torch.norm(dataset, p=2, dim=2, keepdim=True)  # Shape (n, 16, 1)\n",
    "\n",
    "# Normalize by dividing each column by its L2 norm\n",
    "normalized_tensor = dataset / (original_norms + 1e-8)  # Avoid division by zero\n",
    "\n",
    "\n",
    "print(normalized_tensor.shape)\n",
    "print(normalized_tensor[0].numpy())\n",
    "\n",
    "dataset = normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch training\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Transformer Model with Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #def __init__(self, d_model, max_len=16):\n",
    "    def __init__(self, d_model, max_len=sequence_length):\n",
    "\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe.to(x.device)\n",
    "\n",
    "class MidiTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=4, model_dim=128, num_heads=4, num_layers=3, ff_dim=512):\n",
    "        super(MidiTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=ff_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(model_dim, input_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = self.pos_encoder(x)  \n",
    "        x = self.transformer_encoder(x)  \n",
    "        x = self.fc(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.06967059296006575\n",
      "Epoch 10, Loss: 0.0008469862409700186\n",
      "Epoch 20, Loss: 0.001085345895822124\n",
      "Epoch 30, Loss: 0.0003567144606047525\n",
      "Epoch 40, Loss: 0.00042770833608348115\n"
     ]
    }
   ],
   "source": [
    "# Model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MidiTransformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with batches\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)  # Move batch to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)  \n",
    "        loss = criterion(outputs, batch)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.62655044  0.78699994  0.01131537  0.00770239]\n",
      " [ 0.5899809   0.81410915  0.00550886 -0.00443957]\n",
      " [ 0.5851951   0.8241148  -0.00406289  0.00254339]\n",
      " [ 0.6551651   0.7514061   0.0105947   0.00236099]\n",
      " [ 0.6638858   0.750672    0.00851372 -0.0125639 ]\n",
      " [ 0.6247      0.7860938   0.00586439  0.00628362]\n",
      " [ 0.703118    0.7049148   0.00465032  0.00033726]\n",
      " [ 0.6976343   0.71831167  0.00518724  0.00168014]\n",
      " [ 0.65949     0.7619515   0.00664136  0.01138287]\n",
      " [ 0.7150343   0.6810331  -0.00181294  0.00445807]\n",
      " [ 0.66967577  0.735859    0.00511248  0.00125516]\n",
      " [ 0.6692896   0.7451462   0.00161145 -0.00330981]\n",
      " [ 0.64057523  0.7591731   0.00802758 -0.006975  ]\n",
      " [ 0.6596316   0.7605257   0.00998237  0.00095095]\n",
      " [ 0.66638565  0.7403559   0.00117768 -0.01513124]\n",
      " [ 0.66436744  0.74375     0.00600076 -0.00417653]]\n",
      "[[74.         92.          0.9981405   0.06095514]\n",
      " [57.000004   79.          0.99950695  0.03139477]\n",
      " [62.         86.          0.99985623  0.01695542]\n",
      " [81.         93.          0.8263304   0.5631856 ]\n",
      " [74.         82.          0.9892742   0.1460702 ]\n",
      " [78.         97.          0.9857657   0.16812497]\n",
      " [73.         73.          0.9999209   0.01258228]\n",
      " [76.         79.          0.9999016   0.01402594]\n",
      " [71.         78.          0.99994314  0.01066796]\n",
      " [74.         72.          0.99991363  0.01313807]\n",
      " [69.         76.          0.99996614  0.00823017]\n",
      " [73.         79.          0.99982107  0.01891646]\n",
      " [67.         78.          0.9999538   0.00961175]\n",
      " [71.         83.          0.99989355  0.01458731]\n",
      " [66.         76.          0.9999626   0.00865075]\n",
      " [69.         77.          0.99992186  0.01249902]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a new MIDI sequence from a random input\n",
    "random_index = np.random.randint(0, len(dataset))\n",
    "random_sequence = dataset[random_index].unsqueeze(0)\n",
    "random_sequence = dataset[0].unsqueeze(0)\n",
    "\n",
    "random_sequence = random_sequence.to(device)  # Move input to same device\n",
    "generated_sequence = model(random_sequence).detach().cpu().numpy()\n",
    "\n",
    "print(generated_sequence[0])\n",
    "generated_sequence = normalized_tensor * original_norms  # Restore original values\n",
    "generated_sequence = generated_sequence.numpy()\n",
    "print(generated_sequence[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note(start=0.171810, end=0.232765, pitch=74, velocity=92)\n",
      "Note(start=0.173177, end=0.204571, pitch=57, velocity=79)\n",
      "Note(start=0.173526, end=0.190481, pitch=62, velocity=86)\n",
      "Note(start=0.000000, end=0.563186, pitch=81, velocity=93)\n",
      "Note(start=0.162944, end=0.309014, pitch=74, velocity=82)\n",
      "Note(start=0.159435, end=0.327560, pitch=78, velocity=97)\n",
      "Note(start=0.173590, end=0.186173, pitch=73, velocity=73)\n",
      "Note(start=0.173571, end=0.187597, pitch=76, velocity=79)\n",
      "Note(start=0.173613, end=0.184281, pitch=71, velocity=78)\n",
      "Note(start=0.173583, end=0.186721, pitch=74, velocity=72)\n",
      "Note(start=0.173636, end=0.181866, pitch=69, velocity=76)\n",
      "Note(start=0.173491, end=0.192407, pitch=73, velocity=79)\n",
      "Note(start=0.173623, end=0.183235, pitch=67, velocity=78)\n",
      "Note(start=0.173563, end=0.188150, pitch=71, velocity=83)\n",
      "Note(start=0.173632, end=0.182283, pitch=66, velocity=76)\n",
      "Note(start=0.173591, end=0.186090, pitch=69, velocity=77)\n",
      "Generated MIDI saved as generated.mid\n"
     ]
    }
   ],
   "source": [
    "# Convert generated sequence to MIDI\n",
    "def sequence_to_midi(sequence, output_file=\"generated.mid\"):\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=0)  \n",
    "\n",
    "    # Adjust start times to ensure the sequence starts at 0\n",
    "    min_start_time = min(note_data[2] for note_data in sequence[0])\n",
    "    \n",
    "    for note_data in sequence[0]:  # Adjusted to handle batch dimension\n",
    "        pitch, velocity, start, duration = note_data\n",
    "        pitch = int(pitch)  # Ensure pitch is an integer\n",
    "        velocity = int(velocity)  # Ensure velocity is an integer\n",
    "        start = float(start) - min_start_time  # Adjust start time\n",
    "        duration = float(duration)  # Ensure duration is a float\n",
    "        end = start + duration\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=velocity, pitch=pitch, start=start, end=end\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    midi.instruments.append(instrument)\n",
    "    midi.write(output_file)\n",
    "    for noteInformation in midi.instruments[0].notes:\n",
    "        print(noteInformation)\n",
    "    print(f\"Generated MIDI saved as {output_file}\")\n",
    "\n",
    "sequence_to_midi(generated_sequence, \"generated.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
