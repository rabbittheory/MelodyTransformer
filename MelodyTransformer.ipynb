{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "sequence_length=16\n",
    "batch_size=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define scalers for velocity and timing features\n",
    "pitch_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "velocity_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "start_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "duration_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MIDI features (limited to first 50 notes)\n",
    "def extract_midi_features(midi_file, max_notes=50):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    notes = []  # Initialize notes inside the function\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append([\n",
    "                note.pitch, \n",
    "                note.velocity,\n",
    "                note.start, \n",
    "                note.end - note.start\n",
    "            ])\n",
    "            if len(notes) >= max_notes:  # Stop collecting after 50 notes\n",
    "                return np.array(notes)  # Return early\n",
    "\n",
    "    return np.array(notes[:max_notes])  # Ensure no more than 50 notes\n",
    "\n",
    "# Load all MIDI files (including both .midi and .mid)\n",
    "midi_files = glob.glob(\"medium-dataset/*.midi\") + glob.glob(\"smaller-dataset/*.mid\")\n",
    "data = []\n",
    "\n",
    "for f in midi_files:\n",
    "    notes = extract_midi_features(f)\n",
    "    for i in range(0, len(notes) - sequence_length - 1):\n",
    "        data.append(notes[i:i + sequence_length])  # Create 16-note sequences\n",
    "\n",
    "data = [d for d in data if d.shape == (sequence_length, 4)]  # Filter inconsistent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n",
      "[[38.         65.          1.02083333  0.19401042]\n",
      " [41.         68.          1.0625      0.18489583]\n",
      " [45.         72.          1.11067708  0.1484375 ]\n",
      " [50.         82.          1.15364583  0.12239583]\n",
      " [62.         68.          1.16796875  0.11328125]\n",
      " [65.         70.          1.20182292  0.10546875]\n",
      " [69.         75.          1.22786458  0.09375   ]\n",
      " [74.         91.          1.26041667  0.08072917]\n",
      " [74.         87.          1.46223958  0.05598958]\n",
      " [62.         84.          1.6171875   0.1328125 ]\n",
      " [50.         73.          1.63020833  0.12369792]\n",
      " [53.         74.          1.63020833  0.14973958]\n",
      " [74.         92.          1.62369792  0.17447917]\n",
      " [70.         78.          1.8046875   0.04947917]\n",
      " [82.         84.          1.79557292  0.06901042]\n",
      " [70.         83.          1.95572917  0.02734375]]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[(16*4)+2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.tensor(np.array(data), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3300, 16, 4])\n",
      "tensor([[7.4000e+01, 9.2000e+01, 1.0234e+00, 6.2500e-02],\n",
      "        [5.7000e+01, 7.9000e+01, 2.0312e+00, 6.3802e-02],\n",
      "        [6.2000e+01, 8.6000e+01, 2.5339e+00, 4.2969e-02],\n",
      "        [8.1000e+01, 9.3000e+01, 1.5456e+00, 1.0534e+00],\n",
      "        [7.4000e+01, 8.2000e+01, 3.0247e+00, 4.4661e-01],\n",
      "        [7.8000e+01, 9.7000e+01, 3.0156e+00, 5.1432e-01],\n",
      "        [7.3000e+01, 7.3000e+01, 3.5182e+00, 4.4271e-02],\n",
      "        [7.6000e+01, 7.9000e+01, 3.5273e+00, 4.9479e-02],\n",
      "        [7.1000e+01, 7.8000e+01, 3.6615e+00, 3.9062e-02],\n",
      "        [7.4000e+01, 7.2000e+01, 3.6667e+00, 4.8177e-02],\n",
      "        [6.9000e+01, 7.6000e+01, 3.7969e+00, 3.1250e-02],\n",
      "        [7.3000e+01, 7.9000e+01, 3.7852e+00, 7.1615e-02],\n",
      "        [6.7000e+01, 7.8000e+01, 3.9284e+00, 3.7760e-02],\n",
      "        [7.1000e+01, 8.3000e+01, 3.9271e+00, 5.7292e-02],\n",
      "        [6.6000e+01, 7.6000e+01, 4.0638e+00, 3.5156e-02],\n",
      "        [6.9000e+01, 7.7000e+01, 4.0625e+00, 5.0781e-02]])\n",
      "[[73.         58.         10.618489    0.6510417 ]\n",
      " [50.         34.         11.428386    0.91015625]\n",
      " [71.         55.         11.0078125   1.3893229 ]\n",
      " [69.         54.         12.186198    0.3216146 ]\n",
      " [50.         27.         13.1432295   0.5546875 ]\n",
      " [68.         60.         13.0286455   1.046875  ]\n",
      " [59.         35.         13.1223955   1.6367188 ]\n",
      " [76.         65.         13.8151045   1.6419271 ]\n",
      " [49.         35.         14.5963545   0.9401042 ]\n",
      " [57.         37.         14.558594    0.98828125]\n",
      " [73.         59.         15.286458    0.2903646 ]\n",
      " [68.         60.         16.059896    0.85286456]\n",
      " [57.         31.         16.125       0.9270833 ]\n",
      " [69.         51.         16.799479    0.30859375]\n",
      " [49.         37.         16.11849     1.0013021 ]\n",
      " [63.         55.         17.5625      0.8828125 ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset[0])\n",
    "print(dataset[50].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch training\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Transformer Model with Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #def __init__(self, d_model, max_len=16):\n",
    "    def __init__(self, d_model, max_len=sequence_length):\n",
    "\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe.to(x.device)\n",
    "\n",
    "class MidiTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=4, model_dim=128, num_heads=4, num_layers=3, ff_dim=512):\n",
    "        super(MidiTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=ff_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(model_dim, input_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = self.pos_encoder(x)  \n",
    "        x = self.transformer_encoder(x)  \n",
    "        x = self.fc(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 917.625752011359\n",
      "Epoch 10, Loss: 140.33146879408093\n",
      "Epoch 20, Loss: 140.26810083066783\n",
      "Epoch 30, Loss: 140.33954135692062\n",
      "Epoch 40, Loss: 140.2749450425595\n"
     ]
    }
   ],
   "source": [
    "# Model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MidiTransformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with batches\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)  # Move batch to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)  \n",
    "        loss = criterion(outputs, batch)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[60.06596    58.814827    4.5659733   0.39132792]\n",
      "  [58.48512    57.35673     4.4054675   0.40775374]\n",
      "  [60.762115   59.542717    4.6201606   0.38315064]\n",
      "  [59.827644   58.64504     4.5489664   0.45623904]\n",
      "  [58.999317   57.74767     4.4615703   0.39882952]\n",
      "  [58.094154   56.928776    4.279761    0.47441226]\n",
      "  [59.07927    58.011024    4.6278954   0.43505064]\n",
      "  [57.32234    56.069103    4.20523     0.39189267]\n",
      "  [58.514164   57.394146    4.4932437   0.41309863]\n",
      "  [59.92619    58.678883    4.8112893   0.3494756 ]\n",
      "  [59.071262   57.859863    4.3917255   0.3588261 ]\n",
      "  [59.930305   58.717457    4.5944724   0.3869324 ]\n",
      "  [60.78053    59.524166    4.654535    0.38533413]\n",
      "  [59.574783   58.43304     4.640315    0.37986404]\n",
      "  [60.04579    58.93596     4.5089564   0.47225046]\n",
      "  [58.550217   57.371128    4.6780643   0.41523826]]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a new MIDI sequence from a random input\n",
    "random_index = np.random.randint(0, len(dataset))\n",
    "random_sequence = dataset[random_index].unsqueeze(0)\n",
    "random_sequence = dataset[0].unsqueeze(0)\n",
    "\n",
    "random_sequence = random_sequence.to(device)  # Move input to same device\n",
    "generated_sequence = model(random_sequence).detach().cpu().numpy()\n",
    "\n",
    "print(generated_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note(start=0.360743, end=0.752071, pitch=60, velocity=58)\n",
      "Note(start=0.200237, end=0.607991, pitch=58, velocity=57)\n",
      "Note(start=0.414930, end=0.798081, pitch=60, velocity=59)\n",
      "Note(start=0.343736, end=0.799975, pitch=59, velocity=58)\n",
      "Note(start=0.256340, end=0.655170, pitch=58, velocity=57)\n",
      "Note(start=0.074531, end=0.548943, pitch=58, velocity=56)\n",
      "Note(start=0.422665, end=0.857716, pitch=59, velocity=58)\n",
      "Note(start=0.000000, end=0.391893, pitch=57, velocity=56)\n",
      "Note(start=0.288013, end=0.701112, pitch=58, velocity=57)\n",
      "Note(start=0.606059, end=0.955535, pitch=59, velocity=58)\n",
      "Note(start=0.186495, end=0.545321, pitch=59, velocity=57)\n",
      "Note(start=0.389242, end=0.776175, pitch=59, velocity=58)\n",
      "Note(start=0.449305, end=0.834639, pitch=60, velocity=59)\n",
      "Note(start=0.435085, end=0.814949, pitch=59, velocity=58)\n",
      "Note(start=0.303726, end=0.775977, pitch=60, velocity=58)\n",
      "Note(start=0.472834, end=0.888072, pitch=58, velocity=57)\n",
      "Generated MIDI saved as generated.mid\n"
     ]
    }
   ],
   "source": [
    "# Convert generated sequence to MIDI\n",
    "def sequence_to_midi(sequence, output_file=\"generated.mid\"):\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=0)  \n",
    "\n",
    "    # Adjust start times to ensure the sequence starts at 0\n",
    "    min_start_time = min(note_data[2] for note_data in sequence[0])\n",
    "    \n",
    "    for note_data in sequence[0]:  # Adjusted to handle batch dimension\n",
    "        pitch, velocity, start, duration = note_data\n",
    "        pitch = int(pitch)  # Ensure pitch is an integer\n",
    "        velocity = int(velocity)  # Ensure velocity is an integer\n",
    "        start = float(start) - min_start_time  # Adjust start time\n",
    "        duration = float(duration)  # Ensure duration is a float\n",
    "        end = start + duration\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=velocity, pitch=pitch, start=start, end=end\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    midi.instruments.append(instrument)\n",
    "    midi.write(output_file)\n",
    "    for noteInformation in midi.instruments[0].notes:\n",
    "        print(noteInformation)\n",
    "    print(f\"Generated MIDI saved as {output_file}\")\n",
    "\n",
    "sequence_to_midi(generated_sequence, \"generated.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
